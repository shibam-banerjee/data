{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N5QCLaUnrnBV"
   },
   "source": [
    "# Back Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sH5jPVX-rnBd"
   },
   "source": [
    "## 1. loading of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4WT0EJRrnBg",
    "outputId": "90804161-647c-4283-a8c2-27188dd451ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 6)\n",
      "(506, 5) (506,)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import operator\n",
    "with open('data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "print(data.shape)\n",
    "X = data[:, :5]                                                   \n",
    "y = data[:, -1]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GIkq6U0SrnBu"
   },
   "source": [
    "# 2. Computational graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3XnJH-McrnBx"
   },
   "source": [
    "<img src='https://i.imgur.com/seSGbNS.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YRQKYgJrrnB0"
   },
   "source": [
    "<pre>\n",
    "1. if you observe the graph, we are having input features [f1, f2, f3, f4, f5] and 9 weights [w1, w2, w3, w4, w5, w6,    w7, w8, w9]\n",
    "2. the final output of this graph is a value L which is computed as (Y-Y')^2\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "inW-os8IrnB3"
   },
   "source": [
    "### Task 1: Implementing backpropagation and Gradient checking\n",
    "\n",
    "\n",
    "<pre>1. <b>Check this video for better understanding of the computational graphs and back propagation:</b> <a href='https://www.youtube.com/watch?v=i94OvYb6noo#t=1m33s'>https://www.youtube.com/watch?v=i94OvYb6noo</a>\n",
    "</pre>\n",
    "\n",
    "<pre>\n",
    "2. <b>write two functions</b>\n",
    "\n",
    "#you can modify the definition of this function according to your needs\n",
    "<font color='green'>\n",
    "def forward_propagation(X, y, W):\n",
    "        <font color='grey'>\n",
    "        # X: input data point, note that in this assignment you are having 5-d data points\n",
    "        # y: output varible\n",
    "        # W: weight array, its of length 9, W[0] corresponds to w1 in graph, W[1] corresponds to w2 in graph, ..., W[8] corresponds to w9 in graph.\n",
    "        # write code to compute the value of L=(y-y')^2\n",
    "        </font>\n",
    "        return (L, any other variables which you might need to use for back propagation)\n",
    "        <font color='grey'>\n",
    "        # Hint: you can use dict type to store the required intermediate variables \n",
    "        </font>\n",
    "</font>\n",
    "</pre>\n",
    "\n",
    "<pre>\n",
    "# you can modify the definition of this function according to your needs\n",
    "<font color='blue'>\n",
    "def backward_propagation(L, Variables):\n",
    "        <font color='grey'>\n",
    "        # L: the loss we calculated for the current point\n",
    "        # Variables: the outputs of the forward_propagation() function\n",
    "        # write code to compute the gradients of each weight [w1,w2,w3,...,w9]\n",
    "        </font>\n",
    "        return dW\n",
    "        <font color='grey'>\n",
    "        # here dW can be a list, or dict or any other data type wich will have gradients of all the weights\n",
    "        # Hint: you can use dict type to store the required variables \n",
    "        </font>\n",
    "</font>\n",
    "</pre>\n",
    "3. <b> <a href='https://towardsdatascience.com/how-to-debug-a-neural-network-with-gradient-checking-41deec0357a9'>Gradient checking</a></b>:<a href='https://towardsdatascience.com/how-to-debug-a-neural-network-with-gradient-checking-41deec0357a9'>blog link</a> \n",
    "\n",
    "<pre>we know that the derivative of any function is </pre>$$\\lim_{\\epsilon\\to0}\\frac{f(x+\\epsilon)-f(x-\\epsilon)}{2\\epsilon}$$\n",
    "<pre>\n",
    "The definition above can be used as a numerical approximation of the derivative. Taking an epsilon small enough, the calculated approximation will have an error in the range of epsilon squared. \n",
    "\n",
    "In other words, if epsilon is 0.001, the approximation will be off by 0.00001.\n",
    "\n",
    "Therefore, we can use this to approximate the gradient, and in turn make sure that backpropagation is implemented properly. This forms the basis of gradient checking!\n",
    "\n",
    "</pre>\n",
    "\n",
    "<font >\n",
    "lets understand the concept with a simple example:\n",
    "$f(w1,w2,x1,x2)=w_{1}^{2} . x_{1} + w_{2} . x_{2}$ \n",
    "\n",
    "from the above function lets assume $w_{1}=1$, $w_{2}=2$, $x_{1}=3$, $x_{2}=4$ the gradient of $f$ w.r.t $w_{1}$ is\n",
    "\n",
    "\\begin{array} {lcl}\n",
    "\\frac{df}{dw_{1}} = dw_{1} &=&2.w_{1}.x_{1} \\\\& = &2.1.3\\\\& = &6\n",
    "\\end{array}\n",
    "\n",
    "\n",
    "let calculate the aproximate gradient of $w_{1}$ as mentinoned in the above formula and considering $\\epsilon=0.0001$\n",
    "\n",
    "\\begin{array} {lcl}\n",
    "dw_1^{approx} & = & \\frac{f(w1+\\epsilon,w2,x1,x2)-f(w1-\\epsilon,w2,x1,x2)}{2\\epsilon} \\\\ & = & \\frac{((1+0.0001)^{2} . 3 + 2 . 4) - ((1-0.0001)^{2} . 3 + 2 . 4)}{2\\epsilon} \\\\ & = & \\frac{(1.00020001 . 3 + 2 . 4) - (0.99980001. 3 + 2 . 4)}{2*0.0001} \\\\ & = & \\frac{(11.00060003) - (10.99940003)}{0.0002}\\\\ & = & 5.99999999999\n",
    "\\end{array}\n",
    "\n",
    "Then, we apply the following formula for gradient check: <i>gradient_check</i> = \n",
    "$\\frac{\\left\\Vert\\left (dW-dW^{approx}\\rm\\right) \\right\\Vert_2}{\\left\\Vert\\left (dW\\rm\\right) \\right\\Vert_2+\\left\\Vert\\left (dW^{approx}\\rm\\right) \\right\\Vert_2}$\n",
    "\n",
    "The equation above is basically the Euclidean distance normalized by the sum of the norm of the vectors. We use normalization in case that one of the vectors is very small.\n",
    "As a value for epsilon, we usually opt for 1e-7. Therefore, if gradient check return a value less than 1e-7, then it means that backpropagation was implemented correctly. Otherwise, there is potentially a mistake in your implementation. If the value exceeds 1e-3, then you are sure that the code is not correct.\n",
    "\n",
    "in our example: <i>gradient_check</i> $ = \\frac{(6 - 5.999999999994898)}{(6 + 5.999999999994898)} = 4.2514140356330737e^{-13}$\n",
    "\n",
    "you can mathamatically derive the same thing like this\n",
    "\n",
    "\\begin{array} {lcl}\n",
    "dw_1^{approx} & = & \\frac{f(w1+\\epsilon,w2,x1,x2)-f(w1-\\epsilon,w2,x1,x2)}{2\\epsilon} \\\\ & = & \\frac{((w_{1}+\\epsilon)^{2} . x_{1} + w_{2} . x_{2}) - ((w_{1}-\\epsilon)^{2} . x_{1} + w_{2} . x_{2})}{2\\epsilon} \\\\ & = & \\frac{4. \\epsilon.w_{1}. x_{1}}{2\\epsilon} \\\\ & = &  2.w_{1}.x_{1}\n",
    "\\end{array}\n",
    "\n",
    "to do this task you need to write a function \n",
    "<pre>\n",
    "<font color='darkblue'>\n",
    "W = initilize_randomly\n",
    "def gradient_checking(data_point, W):\n",
    "    <font color='grey'>\n",
    "    # compute the L value using forward_propagation()\n",
    "    # compute the gradients of W using backword_propagation()\n",
    "    </font>\n",
    "    approx_gradients = []\n",
    "    for each wi weight value in W:\n",
    "        <font color='grey'>\n",
    "        # add a small value to weight wi, and then find the values of L with the updated weights\n",
    "        # subtract a small value to weight wi, and then find the values of L with the updated weights\n",
    "        # compute the approximation gradients of weight wi\n",
    "        </font>\n",
    "        approx_gradients.append(approximation gradients of weight wi)\n",
    "    <font color='grey'>\n",
    "    # compare the gradient of weights W from backword_propagation() with the aproximation gradients of weights with      gradient_check formula\n",
    "    </font>\n",
    "    return gradient_check\n",
    "</font>\n",
    "NOTE: you can do sanity check by checking all the return values of gradient_checking(), they have to be zero. if not you have bug in your code\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mf1fj5ZernB5"
   },
   "source": [
    "### Task 2: Optimizers\n",
    "\n",
    "1. As a part of this task, you will be implementing 3 type of optimizers(methods to update weight)\n",
    "2. check this video and blog: https://www.youtube.com/watch?v=gYpoJMlgyXA,  http://cs231n.github.io/neural-networks-3/\n",
    "3. use the same computational graph that was mentioned above to do this task\n",
    "4. initilze the 9 weights from normal distribution with mean=0 and std=0.01\n",
    "\n",
    "5. \n",
    "\n",
    "<pre>\n",
    "    for each epoch(1-100):\n",
    "        for each data point in your data:\n",
    "            using the functions forward_propagation() and backword_propagation() compute the gradients of weights\n",
    "            update the weigts with help of gradients  ex: w1 = w1-learning_rate*dw1\n",
    "</pre>\n",
    "\n",
    "6.\n",
    "\n",
    "<pre>\n",
    "<b>task 2.1</b>: you will be implementing the above algorithm with <b>Vanilla update</b> of weights\n",
    "<b>task 2.2</b>: you will be implementing the above algorithm with <b>Momentum update</b> of weights\n",
    "<b>task 2.3</b>: you will be implementing the above algorithm with <b>Adam update</b> of weights\n",
    "</pre>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.normal(0, 0.01, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    '''\n",
    "    Function to calculate sigmoid\n",
    "    \n",
    "    Fx= 1 / 1 + exp^-x\n",
    "\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    '''\n",
    "    Function to calculate tanh\n",
    "    \n",
    "    exp(x) - exp(-x) / exp(x) + exp(-x)\n",
    "    \n",
    "    '''\n",
    "    return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(x,y,w):\n",
    "    '''\n",
    "    Function to calculate Forward Propagation of a MLP\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    L11 = w[0]*x[0]\n",
    "    L12 = w[1]*x[1]\n",
    "    L21 = L11+L12\n",
    "    L22 = L11+L12\n",
    "    L23 = w[2]*x[2]\n",
    "    L24 = w[3]*x[3]\n",
    "    L25 = w[4]*x[4]\n",
    "    L31 = L21*L22\n",
    "    L32 = np.sin(L23)\n",
    "    L33 = L24+L25\n",
    "    L41 = w[5] + L31\n",
    "    L42 = L32*L33\n",
    "    L51 = np.exp(L41)\n",
    "    L52 = w[7] + L42\n",
    "    L61 = w[6] + L51\n",
    "    L62 = sigmoid(L52)\n",
    "    L71 = tanh(L61)\n",
    "    L72 = w[8]*L62\n",
    "    L81 = L71 + L72\n",
    "    y_dash = L81\n",
    "    Loss = (y - y_dash)**2\n",
    "\n",
    "    Loss_dict = {'L11':L11,'L12':L12,'L21':L21,'L22':L22,'L23':L23,'L24':L24,'L25':L25,'L31':L31,'L32':L32,'L33':L33,\n",
    "                'L41':L41,'L42':L42,'L51':L51,'L52':L52,'L61':L61,'L62':L62,'L71':L71,'L72':L72,'L72':L72,'L81':L81,\n",
    "                'y_dash':y_dash,'Loss':Loss} #Storing in a dictionary {Output Name: Value}\n",
    "    \n",
    "    return Loss, y_dash, Loss_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(loss, y_dash, x, y, w, loss_dt):\n",
    "    '''\n",
    "    Function to calculate Backward Propagation of a MLP\n",
    "    \n",
    "    '''\n",
    "    #Calculated Gradients of the given Graph\n",
    "    dl_by_dydash = 2*(y_dash - y)\n",
    "    dydash_by_d071 = 1\n",
    "    d071_by_d061 = (1 - (tanh(loss_dt['L61']))**2)\n",
    "    d061_by_d051 = 1\n",
    "    d051_by_d041 = np.exp(loss_dt['L41'])\n",
    "    d041_by_d031 = 1\n",
    "    d031_by_d021 = loss_dt['L22']\n",
    "    d021_by_d011 = 1\n",
    "    d022_by_d011 = 1\n",
    "    d011_by_dw1 = x[0]\n",
    "    d022_by_d012 = 1\n",
    "    d021_by_d012 = 1\n",
    "    d012_by_dw2 = x[1]\n",
    "    d031_by_d022 = loss_dt['L21']\n",
    "    dydash_by_d072 = 1\n",
    "    d072_by_d062 = w[8]\n",
    "    d062_by_d052 = sigmoid(loss_dt['L52']) * (1 - sigmoid(loss_dt['L52']))\n",
    "    d052_by_d042 = 1\n",
    "    d042_by_d032 = loss_dt['L33']\n",
    "    d032_by_d023 = np.cos(loss_dt['L23'])\n",
    "    d023_by_dw3 = x[2]\n",
    "    d042_by_d033 = loss_dt['L32']\n",
    "    d033_by_d024 = 1\n",
    "    d024_by_dw4 = x[3]\n",
    "    d033_by_d025 = 1\n",
    "    d025_by_dw5 = x[4]\n",
    "    d041_by_dw6 = 1\n",
    "    d061_by_dw7 = 1\n",
    "    d052_by_dw8 = 1\n",
    "    d072_by_dw9 = loss_dt['L62']\n",
    "    \n",
    "    dw1 = dl_by_dydash*dydash_by_d071*d071_by_d061*d061_by_d051*d051_by_d041*d041_by_d031*((d031_by_d021*d021_by_d011*d011_by_dw1)+(d031_by_d022*d022_by_d011*d011_by_dw1))   \n",
    "    dw2 = dl_by_dydash*dydash_by_d071*d071_by_d061*d061_by_d051*d051_by_d041*d041_by_d031*((d031_by_d022*d022_by_d012*d012_by_dw2)+(d031_by_d021*d021_by_d012*d012_by_dw2))\n",
    "    dw3 = dl_by_dydash*dydash_by_d072*d072_by_d062*d062_by_d052*d052_by_d042*d042_by_d032*d032_by_d023*d023_by_dw3\n",
    "    dw4 = dl_by_dydash*dydash_by_d072*d072_by_d062*d062_by_d052*d052_by_d042*d042_by_d033*d033_by_d024*d024_by_dw4\n",
    "    dw5 = dl_by_dydash*dydash_by_d072*d072_by_d062*d062_by_d052*d052_by_d042*d042_by_d033*d033_by_d025*d025_by_dw5\n",
    "    dw6 = dl_by_dydash*dydash_by_d071*d071_by_d061*d061_by_d051*d051_by_d041*d041_by_dw6\n",
    "    dw7 = dl_by_dydash*dydash_by_d071*d071_by_d061*d061_by_dw7\n",
    "    dw8 = dl_by_dydash*dydash_by_d072*d072_by_d062*d062_by_d052*d052_by_dw8\n",
    "    dw9 = dl_by_dydash*dydash_by_d072*d072_by_dw9\n",
    "    \n",
    "    dw = [dw1,dw2,dw3,dw4,dw5,dw6,dw7,dw8,dw9]\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_checking(x,y,w):\n",
    "    '''\n",
    "    Function to check the gradients generated using Function Forward Propagation and Function Backward Propagation\n",
    "    \n",
    "    '''\n",
    "    epsilon = 1e-07\n",
    "    Loss1, y_dash1, Loss_dict1 = forward_propagation(x,y,w)\n",
    "    grad = backward_propagation(Loss1, y_dash1, x, y, w, Loss_dict1)\n",
    "    \n",
    "    approx_gradients = []\n",
    "    gradient_check_list = []\n",
    "    for wi in range(len(w)):\n",
    "        w_new = np.copy(w)\n",
    "        w_new[wi]= w_new[wi] + epsilon #Adding a small value epsilon to wi\n",
    "        w_new_n = np.copy(w)\n",
    "        w_new_n[wi] = w_new_n[wi] - epsilon #Subtracting a small value epsilon to wi\n",
    "        loss_p, yy, Ll = forward_propagation(x,y,w_new)\n",
    "        loss_n, yy, Ll = forward_propagation(x,y,w_new_n)\n",
    "        grad_approx = (loss_p - loss_n)/(2*epsilon) #Approximated grad value\n",
    "        approx_gradients.append(grad_approx)\n",
    "        \n",
    "        diff = list(map(operator.sub, approx_gradients, grad))\n",
    "        numerator = np.linalg.norm(diff) #L2-norm\n",
    "        denominator = np.linalg.norm(grad) + np.linalg.norm(approx_gradients)\n",
    "    \n",
    "        gradient_check = numerator/denominator\n",
    "        gradient_check_list.append(gradient_check)\n",
    "    \n",
    "        if gradient_check < 1e-07:\n",
    "            print('The Gradient Check is Correct and Successful')\n",
    "        else:\n",
    "            print('There is a Mistake')\n",
    "        \n",
    "    \n",
    "    return gradient_check_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Gradient Check is Correct and Successful\n",
      "The Gradient Check is Correct and Successful\n",
      "The Gradient Check is Correct and Successful\n",
      "The Gradient Check is Correct and Successful\n",
      "The Gradient Check is Correct and Successful\n",
      "The Gradient Check is Correct and Successful\n",
      "The Gradient Check is Correct and Successful\n",
      "The Gradient Check is Correct and Successful\n",
      "The Gradient Check is Correct and Successful\n",
      "\n",
      "Gradient Check:\n",
      " [4.4730685262425185e-10, 1.1672961411351353e-09, 1.327029028349624e-09, 1.458393737895507e-09, 1.5756787970160823e-09, 1.3653765007918224e-09, 1.1893118941174437e-09, 1.2090543376931965e-09, 1.089186219076824e-09]\n"
     ]
    }
   ],
   "source": [
    "W = np.random.normal(0, 0.01, 9)\n",
    "datapoint = 1\n",
    "\n",
    "gc = gradient_checking(X[datapoint],y[datapoint],W)\n",
    "print('\\nGradient Check:\\n',gc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2.1: Vanilla Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "w = np.random.normal(0, 0.01, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated value of loss is 0.6921482822190134 in Epoch 1\n",
      "The updated value of loss is 0.6905156026955854 in Epoch 2\n",
      "The updated value of loss is 0.6888901531569488 in Epoch 3\n",
      "The updated value of loss is 0.6872718820676638 in Epoch 4\n",
      "The updated value of loss is 0.6856607383727135 in Epoch 5\n",
      "The updated value of loss is 0.6840566714921618 in Epoch 6\n",
      "The updated value of loss is 0.682459631315883 in Epoch 7\n",
      "The updated value of loss is 0.6808695681983529 in Epoch 8\n",
      "The updated value of loss is 0.6792864329535092 in Epoch 9\n",
      "The updated value of loss is 0.677710176849673 in Epoch 10\n",
      "The updated value of loss is 0.676140751604539 in Epoch 11\n",
      "The updated value of loss is 0.6745781093802221 in Epoch 12\n",
      "The updated value of loss is 0.6730222027783707 in Epoch 13\n",
      "The updated value of loss is 0.6714729848353415 in Epoch 14\n",
      "The updated value of loss is 0.6699304090174298 in Epoch 15\n",
      "The updated value of loss is 0.6683944292161634 in Epoch 16\n",
      "The updated value of loss is 0.6668649997436564 in Epoch 17\n",
      "The updated value of loss is 0.6653420753280154 in Epoch 18\n",
      "The updated value of loss is 0.6638256111088067 in Epoch 19\n",
      "The updated value of loss is 0.66231556263258 in Epoch 20\n",
      "The updated value of loss is 0.6608118858484461 in Epoch 21\n",
      "The updated value of loss is 0.65931453710371 in Epoch 22\n",
      "The updated value of loss is 0.6578234731395576 in Epoch 23\n",
      "The updated value of loss is 0.6563386510867966 in Epoch 24\n",
      "The updated value of loss is 0.654860028461648 in Epoch 25\n",
      "The updated value of loss is 0.6533875631615933 in Epoch 26\n",
      "The updated value of loss is 0.651921213461268 in Epoch 27\n",
      "The updated value of loss is 0.6504609380084095 in Epoch 28\n",
      "The updated value of loss is 0.6490066958198524 in Epoch 29\n",
      "The updated value of loss is 0.6475584462775736 in Epoch 30\n",
      "The updated value of loss is 0.6461161491247882 in Epoch 31\n",
      "The updated value of loss is 0.6446797644620872 in Epoch 32\n",
      "The updated value of loss is 0.6432492527436287 in Epoch 33\n",
      "The updated value of loss is 0.6418245747733737 in Epoch 34\n",
      "The updated value of loss is 0.6404056917013641 in Epoch 35\n",
      "The updated value of loss is 0.6389925650200525 in Epoch 36\n",
      "The updated value of loss is 0.6375851565606702 in Epoch 37\n",
      "The updated value of loss is 0.6361834284896442 in Epoch 38\n",
      "The updated value of loss is 0.6347873433050539 in Epoch 39\n",
      "The updated value of loss is 0.6333968638331352 in Epoch 40\n",
      "The updated value of loss is 0.6320119532248208 in Epoch 41\n",
      "The updated value of loss is 0.6306325749523287 in Epoch 42\n",
      "The updated value of loss is 0.6292586928057858 in Epoch 43\n",
      "The updated value of loss is 0.6278902708898977 in Epoch 44\n",
      "The updated value of loss is 0.6265272736206552 in Epoch 45\n",
      "The updated value of loss is 0.6251696657220809 in Epoch 46\n",
      "The updated value of loss is 0.6238174122230149 in Epoch 47\n",
      "The updated value of loss is 0.6224704784539401 in Epoch 48\n",
      "The updated value of loss is 0.6211288300438438 in Epoch 49\n",
      "The updated value of loss is 0.6197924329171187 in Epoch 50\n",
      "The updated value of loss is 0.6184612532904984 in Epoch 51\n",
      "The updated value of loss is 0.6171352576700323 in Epoch 52\n",
      "The updated value of loss is 0.6158144128480948 in Epoch 53\n",
      "The updated value of loss is 0.6144986859004292 in Epoch 54\n",
      "The updated value of loss is 0.6131880441832294 in Epoch 55\n",
      "The updated value of loss is 0.6118824553302534 in Epoch 56\n",
      "The updated value of loss is 0.6105818872499735 in Epoch 57\n",
      "The updated value of loss is 0.6092863081227581 in Epoch 58\n",
      "The updated value of loss is 0.6079956863980871 in Epoch 59\n",
      "The updated value of loss is 0.6067099907918027 in Epoch 60\n",
      "The updated value of loss is 0.6054291902833873 in Epoch 61\n",
      "The updated value of loss is 0.6041532541132802 in Epoch 62\n",
      "The updated value of loss is 0.6028821517802201 in Epoch 63\n",
      "The updated value of loss is 0.6016158530386206 in Epoch 64\n",
      "The updated value of loss is 0.6003543278959791 in Epoch 65\n",
      "The updated value of loss is 0.5990975466103114 in Epoch 66\n",
      "The updated value of loss is 0.5978454796876199 in Epoch 67\n",
      "The updated value of loss is 0.5965980978793886 in Epoch 68\n",
      "The updated value of loss is 0.5953553721801109 in Epoch 69\n",
      "The updated value of loss is 0.5941172738248425 in Epoch 70\n",
      "The updated value of loss is 0.5928837742867835 in Epoch 71\n",
      "The updated value of loss is 0.5916548452748909 in Epoch 72\n",
      "The updated value of loss is 0.5904304587315166 in Epoch 73\n",
      "The updated value of loss is 0.589210586830073 in Epoch 74\n",
      "The updated value of loss is 0.5879952019727254 in Epoch 75\n",
      "The updated value of loss is 0.5867842767881122 in Epoch 76\n",
      "The updated value of loss is 0.5855777841290906 in Epoch 77\n",
      "The updated value of loss is 0.5843756970705084 in Epoch 78\n",
      "The updated value of loss is 0.5831779889069993 in Epoch 79\n",
      "The updated value of loss is 0.58198463315081 in Epoch 80\n",
      "The updated value of loss is 0.5807956035296414 in Epoch 81\n",
      "The updated value of loss is 0.5796108739845273 in Epoch 82\n",
      "The updated value of loss is 0.5784304186677255 in Epoch 83\n",
      "The updated value of loss is 0.5772542119406424 in Epoch 84\n",
      "The updated value of loss is 0.5760822283717734 in Epoch 85\n",
      "The updated value of loss is 0.5749144427346742 in Epoch 86\n",
      "The updated value of loss is 0.573750830005949 in Epoch 87\n",
      "The updated value of loss is 0.5725913653632643 in Epoch 88\n",
      "The updated value of loss is 0.5714360241833865 in Epoch 89\n",
      "The updated value of loss is 0.5702847820402372 in Epoch 90\n",
      "The updated value of loss is 0.5691376147029765 in Epoch 91\n",
      "The updated value of loss is 0.5679944981341041 in Epoch 92\n",
      "The updated value of loss is 0.56685540848758 in Epoch 93\n",
      "The updated value of loss is 0.5657203221069721 in Epoch 94\n",
      "The updated value of loss is 0.5645892155236202 in Epoch 95\n",
      "The updated value of loss is 0.5634620654548214 in Epoch 96\n",
      "The updated value of loss is 0.5623388488020372 in Epoch 97\n",
      "The updated value of loss is 0.5612195426491184 in Epoch 98\n",
      "The updated value of loss is 0.5601041242605531 in Epoch 99\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "epoch = range(1,100)\n",
    "loss_list = []\n",
    "w1 = np.copy(w)\n",
    "for i in epoch:\n",
    "    for j in range(len(X)):\n",
    "        loss1, y_dash_val, loss_dict1 = forward_propagation(X[j],y[j],w1)\n",
    "        dw = backward_propagation(loss1, y_dash_val, X[j], y[j], w1, loss_dict1)\n",
    "    w1 = w1-[x * learning_rate for x in dw]\n",
    "    loss_list.append(loss1)\n",
    "    print('The updated value of loss is {} in Epoch {}'.format(loss1,i))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(4,3))\n",
    "plt.plot(epoch,loss_list)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Epoch vs Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2.2: Momentum Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated value of w is 0.6921482822190134 in Epoch 1\n",
      "The updated value of w is 0.6905156026955854 in Epoch 2\n",
      "The updated value of w is 0.6874270853084302 in Epoch 3\n",
      "The updated value of w is 0.6830528118907335 in Epoch 4\n",
      "The updated value of w is 0.6775542955723017 in Epoch 5\n",
      "The updated value of w is 0.6710832027715771 in Epoch 6\n",
      "The updated value of w is 0.6637805296185321 in Epoch 7\n",
      "The updated value of w is 0.655776159407103 in Epoch 8\n",
      "The updated value of w is 0.647188732620878 in Epoch 9\n",
      "The updated value of w is 0.6381257672138619 in Epoch 10\n",
      "The updated value of w is 0.628683973604291 in Epoch 11\n",
      "The updated value of w is 0.6189497158310816 in Epoch 12\n",
      "The updated value of w is 0.6089995772159075 in Epoch 13\n",
      "The updated value of w is 0.5989009954445734 in Epoch 14\n",
      "The updated value of w is 0.588712938077126 in Epoch 15\n",
      "The updated value of w is 0.5784865950231909 in Epoch 16\n",
      "The updated value of w is 0.56826606942951 in Epoch 17\n",
      "The updated value of w is 0.5580890527083423 in Epoch 18\n",
      "The updated value of w is 0.5479874731026496 in Epoch 19\n",
      "The updated value of w is 0.537988110270205 in Epoch 20\n",
      "The updated value of w is 0.5281131709198094 in Epoch 21\n",
      "The updated value of w is 0.5183808226022212 in Epoch 22\n",
      "The updated value of w is 0.5088056844027546 in Epoch 23\n",
      "The updated value of w is 0.4993992745588615 in Epoch 24\n",
      "The updated value of w is 0.49017041598906 in Epoch 25\n",
      "The updated value of w is 0.4811256014205209 in Epoch 26\n",
      "The updated value of w is 0.4722693202879226 in Epoch 27\n",
      "The updated value of w is 0.46360434988718335 in Epoch 28\n",
      "The updated value of w is 0.4551320134403985 in Epoch 29\n",
      "The updated value of w is 0.44685240779364127 in Epoch 30\n",
      "The updated value of w is 0.4387646034532104 in Epoch 31\n",
      "The updated value of w is 0.4308668195900034 in Epoch 32\n",
      "The updated value of w is 0.42315657652351824 in Epoch 33\n",
      "The updated value of w is 0.4156308280506811 in Epoch 34\n",
      "The updated value of w is 0.4082860758213623 in Epoch 35\n",
      "The updated value of w is 0.4011184677907285 in Epoch 36\n",
      "The updated value of w is 0.3941238826049587 in Epoch 37\n",
      "The updated value of w is 0.3872980016061644 in Epoch 38\n",
      "The updated value of w is 0.3806363699780114 in Epoch 39\n",
      "The updated value of w is 0.37413444839781845 in Epoch 40\n",
      "The updated value of w is 0.36778765641532507 in Epoch 41\n",
      "The updated value of w is 0.361591408643594 in Epoch 42\n",
      "The updated value of w is 0.355541144723984 in Epoch 43\n",
      "The updated value of w is 0.3496323539147003 in Epoch 44\n",
      "The updated value of w is 0.3438605950507357 in Epoch 45\n",
      "The updated value of w is 0.3382215125315925 in Epoch 46\n",
      "The updated value of w is 0.33271084891133423 in Epoch 47\n",
      "The updated value of w is 0.32732445459259474 in Epoch 48\n",
      "The updated value of w is 0.32205829506142897 in Epoch 49\n",
      "The updated value of w is 0.31690845604262013 in Epoch 50\n",
      "The updated value of w is 0.3118711469045138 in Epoch 51\n",
      "The updated value of w is 0.30694270259802237 in Epoch 52\n",
      "The updated value of w is 0.3021195843754198 in Epoch 53\n",
      "The updated value of w is 0.29739837950041836 in Epoch 54\n",
      "The updated value of w is 0.2927758001311718 in Epoch 55\n",
      "The updated value of w is 0.28824868153185995 in Epoch 56\n",
      "The updated value of w is 0.28381397974585354 in Epoch 57\n",
      "The updated value of w is 0.27946876884381433 in Epoch 58\n",
      "The updated value of w is 0.2752102378430259 in Epoch 59\n",
      "The updated value of w is 0.2710356873794908 in Epoch 60\n",
      "The updated value of w is 0.2669425262015785 in Epoch 61\n",
      "The updated value of w is 0.2629282675429953 in Epoch 62\n",
      "The updated value of w is 0.2589905254233715 in Epoch 63\n",
      "The updated value of w is 0.2551270109166178 in Epoch 64\n",
      "The updated value of w is 0.2513355284201922 in Epoch 65\n",
      "The updated value of w is 0.2476139719524541 in Epoch 66\n",
      "The updated value of w is 0.24396032150013722 in Epoch 67\n",
      "The updated value of w is 0.2403726394336327 in Epoch 68\n",
      "The updated value of w is 0.2368490670040445 in Epoch 69\n",
      "The updated value of w is 0.2333878209328421 in Epoch 70\n",
      "The updated value of w is 0.22998719010226848 in Epoch 71\n",
      "The updated value of w is 0.2266455323524258 in Epoch 72\n",
      "The updated value of w is 0.22336127138907014 in Epoch 73\n",
      "The updated value of w is 0.22013289380459236 in Epoch 74\n",
      "The updated value of w is 0.21695894621333514 in Epoch 75\n",
      "The updated value of w is 0.21383803250134586 in Epoch 76\n",
      "The updated value of w is 0.2107688111897605 in Epoch 77\n",
      "The updated value of w is 0.20774999291031454 in Epoch 78\n",
      "The updated value of w is 0.20478033799089304 in Epoch 79\n",
      "The updated value of w is 0.2018586541485903 in Epoch 80\n",
      "The updated value of w is 0.1989837942873864 in Epoch 81\n",
      "The updated value of w is 0.19615465439729415 in Epoch 82\n",
      "The updated value of w is 0.19337017155163402 in Epoch 83\n",
      "The updated value of w is 0.19062932199895957 in Epoch 84\n",
      "The updated value of w is 0.18793111934608484 in Epoch 85\n",
      "The updated value of w is 0.1852746128286181 in Epoch 86\n",
      "The updated value of w is 0.18265888566541164 in Epoch 87\n",
      "The updated value of w is 0.18008305349335238 in Epoch 88\n",
      "The updated value of w is 0.17754626287897587 in Epoch 89\n",
      "The updated value of w is 0.17504768990345096 in Epoch 90\n",
      "The updated value of w is 0.17258653881755606 in Epoch 91\n",
      "The updated value of w is 0.17016204076337152 in Epoch 92\n",
      "The updated value of w is 0.16777345255950965 in Epoch 93\n",
      "The updated value of w is 0.16542005554680259 in Epoch 94\n",
      "The updated value of w is 0.1631011544914978 in Epoch 95\n",
      "The updated value of w is 0.160816076543107 in Epoch 96\n",
      "The updated value of w is 0.15856417024417963 in Epoch 97\n",
      "The updated value of w is 0.1563448045893834 in Epoch 98\n",
      "The updated value of w is 0.15415736813139114 in Epoch 99\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "v = np.zeros(len(w))\n",
    "epoch = range(1,100)\n",
    "mu = 0.9\n",
    "loss_list = []\n",
    "w2 = np.copy(w)\n",
    "for i in epoch:\n",
    "    for j in range(len(X)):\n",
    "        loss1, y_dash_val, loss_dict1 = forward_propagation(X[j],y[j],w2)\n",
    "        dw = backward_propagation(loss1, y_dash_val, X[j], y[j], w2, loss_dict1)\n",
    "    v = mu * v - [x * learning_rate for x in dw]\n",
    "    w2 = w2 + v\n",
    "    loss_list.append(loss1)\n",
    "    print('The updated value of w is {} in Epoch {}'.format(loss1,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARMAAADgCAYAAAAg2IK7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3wUBf7/8dcnhQQIhBZCChDpHQIIIqg0BVFRT0Wqgu1UsFf0vqen3s/OIYjtRORUxIKniCgqTUGk9yZVOgGkC0jg8/tjJt6KaYSdzG7yeT4e83Bndnb2vYP7yczszHxEVTHGmDMV4XcAY0zRYMXEGBMUVkyMMUFhxcQYExRWTIwxQWHFxBgTFFZMDAAioiJSy+8cfhORx0XkXb9zhCMrJiFIRDaKyBERORQwvOx3rmASkTS3gEX58N5vi8hv7nr9RUS+EZF6BVjORhHp7EXGcGTFJHRdpqpxAcMgvwMVMc+pahyQCmQAb/sbJ/xZMQkzItJfRGaKyHAR2S8iq0SkU8DzySIy3v2Lu1ZEbg54LlJEHhGRdSJyUETmi0jVgMV3FpE1IrJXREaIiGTz/snuVlOFgGnpIrJbRKJFpJaITHez7RaRDwrwGWNEZKiIbHOHoSIS4z5XSUQmiMg+9zN+LyIR7nMPichW97OtDlwvOVHVX4ExQKMcsnQXkeXu+00Tkfru9HeAasDn7hbOg6f7OYsaKybhqTWwHqgEPAZ8EvDlfh/YAiQDVwP/L+BLdS/QC+gGlAVuAH4NWO6lwNlAU6AH0OXUN1bVbcAs4KqAyb2Bj1X1OPAk8DVQHuev/vACfL5HgXOAZm6WVsDf3Ofucz9fApAIPAKoiNQFBgFnq2oZN/vGvN5IROKAPsDCbJ6rg7M+73bfbyJO8Sihqv2ATfxvC/K5AnzOIsWKSej61P1rmDXcHPBcBjBUVY+r6gfAauASdyujHfCQqh5V1UXAm0A/93U3AX9T1dXqWKyqewKW+4yq7lPVTcBUnC9zdsbgFCXcrZee7jSA40B1INnNMKMAn70P8ISqZqjqLuAfAZ/hOJAEVHc///fqXGB2AogBGohItKpuVNV1ubzH/SKyD1gLxAH9s5nnWuALVf3GLZQvACWBcwvwmYo8Kyah6wpVLRcw/Dvgua36xys0f8bZEkkGflHVg6c8l+I+rgrk9gXbEfD4V5wvWXY+BtqISDJwPqDA9+5zDwICzHF3D27I5f1ykuzmzpL1+QCexykAX4vIehF5GEBV1+JsQTwOZIjIWDdfTl5w12sVVe2eQ+H5Qw5VPQls5n/r0wSwYhKeUk45nlEN2OYOFUSkzCnPbXUfbwZqnumbq+o+nF2ZHji7OO9nFTdV3aGqN6tqMvBX4JUC/OS8DWfrJkvW50NVD6rqfapaA7gMuDdrN05Vx6hqO/e1Cjxb4A+ZTQ53nVflf+vTLrkPYMUkPFUG7nQPeF4D1Acmqupm4AfgaRGJFZEmwI3Ae+7r3gSeFJHa4mgiIhULmGEMcB3OsZOsXRxE5BoRSXVH9+J84U7kspwYN2vWEIFznOJvIpIgIpWAvwPvusu/1D3IK8ABd9knRKSuiHR0D9QeBY7k8b758SHO7mMnEYnGOV5zDGcdA+wEapzhexQZVkxCV9avBFnDfwOemw3UBnYD/wSuDjj20QtIw/mr+l/gMVX9xn1uCM4X5GucL+JInGMABTHezbBTVRcHTD8bmC0ih9x57lLVDbks5xDOFz9r6Ag8BcwDlgBLgQXuNNz3/NZ93SzgFVWdhnO85BmcdbIDp+A+UsDPBoCqrgb64hxE3o2zJXSZqv7mzvI0TtHbJyL3n8l7FQViN0cKLyLSH7jJ3Zw3JmTYlokxJiismBhjgsJ2c4wxQWFbJsaYoLBiYowJikK//PtMVapUSdPS0nJ8/vDhw5QuXbrwAhVQOOS0jMETDjnzyjh//vzdqpqQ4wyq6tkAdMW5bmQt8HA2z/8LWOQOPwH78lpmixYtNDdTp07N9flQEQ45LWPwhEPOvDIC8zSX76ZnWyYiEgmMAC7EucpzroiMV9UVAYXsnoD57wDSvcpjjPGWl8dMWgFrVXW9OmcMjgUuz2X+XjinURtjwpCXxSQF58KyLFvI4WpLEakOnAVM8TCPMcZDXh6A/dNdusj5KsueODfXyfbCLBG5BbgFIDExkWnTpuX4pocOHcr1+VARDjktY/CEQ84zzehlMdmCc7l2llTcy8iz0RMYmNOCVPUN4A2Ali1bavv27XN802nTpnG0Ul1mrdtDs2rlODutAqnlS51uds9NmzaN3D5HKLCMwRMOOc80o5fFZC5QW0TOwrn/Q0+ce1/8gXu7vfI4V4AGxbpdh/lo/hZGz3Lua9O2VkX6nZNGl4aJZHNbU2NMEHhWTFQ1U0QGAZOASOAtVV0uIk/g/MQ03p21FzDW/ekpKAZ2qMWtF9RkTcZBvl2xkzGzN3Hru/NpUb08j1/WkMap8cF6K2OMy9OT1lR1Is5NeAOn/f2U8ce9eO/ICKFelbLUq1KW29rX4uP5m3l+0mq6j5jBHR1qcWen2kRF2gnAxgRLsfg2RUYI155djSn3t+cv6akMm7KWnm/8SMaBo35HM6bIKBbFJEvZ2Ghe7NGUodc2Y8X2A1wxYiardhzwO5YxRUKxKiZZrkhP4cO/tiHzpHL1q7OYtW5P3i8yxuSqWBYTgEYp8Xw6sC1V4mMZ8PYcZqzZ7XckY8JasS0mAMnlSjL2lnNIq1iaG0bP5bufdvkdyZiwVayLCUCluBjG3nIONRPiuOWdeczb+IvfkYwJS8W+mACUK1WCd25sRXJ8SQaMmsvybfv9jmRM2LFi4qoUF8M7N7UmLjaKAaPmsnXfEb8jGRNWrJgESClXkrcHtOLIbycYMGoO+48c9zuSMWHDiskp6lYpw+v9WrBh92EGjVlA5omTfkcyJixYMcnGubUq8c8rG/P9mt089cVKv+MYExbC7obShaVHy6r8tOMgb87YQJ3EMvRuXc3vSMaENNsyycXgbvW5oE4Cj41fxvyf9/odx5iQZsUkF5ERwrCe6STFl+S2d+fbhYHG5MKKSR7iS0Xzer8WHDyaycAxCzhuB2SNyZYVk3yon1SWZ65qzNyNe3n2y1V+xzEmJFkxyafLm6VwfZvqvDljAxOXbvc7jjEhx4rJaXj0kgY0q1qOBz9ewobdh/2OY0xIsWJyGkpERfBy73QiI4SB7y3g6PFsO3MYUyx5WkxEpKuIrBaRtSLycA7z9BCRFSKyXETGeJknGFLLl2JIj6as2H6AJyasyPsFxhQTnhWTgF7DFwMNgF4i0uCUeWoDg4G2qtoQuNurPMHUqX4if72gBmNmb+LzxTm1AjKmePG71/DNwAhV3Qugqhke5gmq+y+qS/Nq5Rj8yVI22vETY3zvNVwHqCMiM0XkRxHp6mGeoIqOjGB47+ZERgiD3l/AsUw7fmKKNwli76s/LljkGqCLqt7kjvcDWqnqHQHzTACOAz1w2od+DzRS1X2nLCuw13CLsWPH5vi+hw4dIi4uLsifJmcLMzJ5acExLqweRZ/6Mfl+XWHnLAjLGDzhkDOvjB06dJivqi1znEFVPRmANsCkgPHBwOBT5nkN6B8wPhk4O7fltmjRQnMzderUXJ/3wmOfLdPqD03Qr5fvyPdr/Mh5uixj8IRDzrwy4nTizPG76eVuzu+9hkWkBE6v4fGnzPMp0AFARCrh7Pas9zCTJwZ3q0fD5LLc/9Fittkd2kwx5VkxUdVMIKvX8ErgQ3V7DYtId3e2ScAeEVkBTAUeUNWwa2ITExXJy72bk3niJHePXWQ3VDLFkqfnmajqRFWto6o1VfWf7rS/q9u03N16uldVG6hqY1XN+WBIiDurUmmeurIRczb+wrApa/2OY0yhszNgg+jK9FSuap7K8Clr+GGdNfUyxYsVkyB74vKGnFWpNHePXcSeQ8f8jmNMobFiEmSlY6J4uVdz9h05zn0fLebkSW9+ejcm1Fgx8UCD5LL83yX1mbZ6FyNnbPA7jjGFwoqJR/qeU50uDRN59qtVLNq8L+8XGBPmrJh4RER47qqmJJaNZdCYBdbQyxR5Vkw8FF8qmmG90tm+/yiDP1mSdZavMUWSFROPtahenge61GXi0h28O3uT33GM8YwVk0Jwy3k1aF83gScnrGDZ1v1+xzHGE1ZMCkFEhDCkRzMqlCrBoDELOHjUjp+YoseKSSGpULoEw3uns3nvER7+ZKkdPzFFjhWTQnR2WgXuv6guXyzZzuRNmX7HMSaorJgUsr+eX4MOdRMYu+o3lmyx809M0WHFpJBlHT+JjxFuf28B+379ze9IxgSFFRMflC9dgtubxbDzwFHu+9Cu3zFFgxUTn9QsF8nfLmnA5FUZvDp9nd9xjDljVkx8dF2b6nRvmsyLX69m5lq7/4kJb1ZMfCQiPP2XxtRMiOOO9xey1e4fa8KYFROflY6J4rV+Lfgt8yS3vzvf+hebsOVrr2ER6S8iu0RkkTvc5GWeUFUzIY4XezRl8Zb9PPbZcjuhzYQlX3sNuz5Q1Wbu8KZXeUJdl4ZVGNShFh/M28yYOXZBoAk/fvcaNgHuubAO7esm8Pj45czb+IvfcYw5LV62B70a6Kp/bA/aWlUHBczTH3ga2AX8BNyjqpuzWVbItgctqJxyHj6uPDHrCEcy4fFzY6kQ699hrXBYl+GQEcIjZyi3B70GeDNgvB8w/JR5KgIx7uNbgSl5LTcU24MWRG45f9pxQBv835d66bDv9chvmYUX6hThsC7DIaNqeOQM5fagW4CqAeOpwLZTCtkeVc3qB/FvoIWHecJG7cQyDO2ZztKt+3lonN2hzYQHX3sNi0hSwGh3nDaiBriwQSL3X1SHzxZt45VpdoasCX1RXi1YVTNFJKvXcCTwlrq9hnE2l8YDd7p9hzOBX4D+XuUJRwM71GJNxiGen7SamglxdG1Uxe9IxuTIs2ICTq9hYOIp0/4e8HgwMNjLDOFMRHj2qib8vOdX7vlgEanl29AoJd7vWMZky86ADXGx0ZG8cV0LKpQuwY2j57Jj/1G/IxmTLSsmYaBymVjevL4lh45mcuPouRw+ZndpM6HHikmYqJ9Ulpf7NGfVjoPc8f5CMk+c9DuSMX9gxSSMdKhbmScub8iUVRk8/rldw2NCi6cHYE3w9WldnU2//Mrr09eTXK4kt7ev5XckYwArJmHpoS712L7vKM99tZrEMrFc1SLV70jGWDEJRxERwvPXNGH3oWM8NG4JlcrEcEGdBL9jmWIuX8dMRKSmiMS4j9uLyJ0iUs7baCY3MVGRvNavBbUTy3Dbu/NZtNnaZhh/5fcA7DjghIjUAkYCZwFjPEtl8qVsbDSjB5xNxbgSDBg1h7UZB/2OZIqx/BaTk6qaCVwJDFXVe4CkPF5jCkHlsrG8c0NrIiMi6DdyDlv2/up3JFNM5beYHBeRXsD1wAR3WrQ3kczpSqtUmv/c0IpDxzLpN3IOuw4ey/tFxgRZfovJAKAN8E9V3SAiZwHvehfLnK4GyWUZ1f9sduw/Sr+Rs61ToCl0+SomqrpCVe9U1fdFpDxQRlWf8TibOU0t0yrw7+tasn7XYa5/aw4Hjx73O5IpRvL7a840ESkrIhWAxcAoERnibTRTEO1qV2JEn+Ys33aAAaPsOh5TePK7mxOvqgeAvwCjVLUF0Nm7WOZMXNggkWG90lm4eR83vD2XI79ZLx7jvfwWkyj3rmg9+N8BWBPCujVOYkiPpszd+IsVFFMo8ltMnsC5Y9o6VZ0rIjWANd7FMsFwebMUXuzRlB837OHG0VZQjLfyewD2I1Vtoqq3uePrVfUqb6OZYLgyPZUhPZoya/0eBrw9x46hGM/k9wBsqoj8V0QyRGSniIwTkTyvLsurPWjAfFeLiIpIzj05TIFdmZ7K0GubMXfjXvuVx3gmv7s5o3DuLJ8MpACfu9NylN/2oCJSBrgTmJ3/2OZ0Xd4sheG90lm0eR9937TzUEzw5beYJKjqKFXNdIe3gbwuU81ve9AngecAu7mpx7o1TuK1vi1Yuf0gPd/40c6UNUGV32KyW0T6ikikO/QF9uTxmhQgsNXnFnfa70QkHaiqqvYLUSHp3CCRkf1bsnHPYXq8Psuu5TFBk69ewyJSDXgZ55R6BX4A7lTVTbm85hqgi/6x13ArVb3DHY8ApgD9VXWjiEwD7lfVedksq9j0Gi4sa/aeYMj8o5SMEu5vGUty3J//rvidMT/CISOER07feg0Dd+fxfBtgUsD4YGBwwHg8sBvY6A5HcdqHtsxtucWh13BhWb51v7Z48htt+o9JuuDnX/70fChkzEs4ZFQNj5x+9hq+N4/nc20Pqqr7VbWSqqapahrwI9Bds9kyMd5okFyWcbe1oWxsNL3/PZupqzP8jmTC2JkUE8ntSXXuf5LVHnQl8KG67UHdlqAmBFSvWJpxt51LjYTS3DR6Hh/O3Zz3i4zJxpncAzbPgy2aR3vQU6a3P4Ms5gwklInhg7+24fb3FvDguCVs3XeEuzvX9juWCTO5FhMROUj2RUOAkp4kMr6Ii4li5PUtGfzJUl6avIbNe3+lWyXry2PyL9dioqplCiuI8V90ZATPX92EahVKMeSbn1hRIYKW5/xGuVIl/I5mwoB19DN/ICLc2ak2Q69txtq9J7nylR9Yv+uQ37FMGLBiYrJ1RXoKD7WKZf+R41wxYibfr9nldyQT4qyYmBzVLh/JZwPbkhRfkv6j5jJq5gbrb2xyZMXE5KpqhVKMu/1cOtarzD8+X8EDHy/h6HG7L4r5MysmJk9xMVG83rcFd3Wqzcfzt3Dt67PYtu+I37FMiLFiYvIlIkK458I6vN6vBet2Heay4TP4Yd1uv2OZEGLFxJyWLg2r8OnAtpQvXYK+b87m1WnrOHnSjqMYKyamAGpVjuPTgW3p1jiJZ79axc3/mWc3WzJWTEzBxMVEMbxXOo9f1oDv1uzikmEzWLBpr9+xjI+smJgCExH6tz2Lj289FxHo8dosXp9uuz3FlRUTc8aaVi3HF3ecx4UNEnn6y1X0f3uu3RKyGLJiYoIivlQ0r/RpzlNXNGL2+j1c/NJ3TF1l90cpTqyYmKAREfqeU53P72hHpbgYBrw9l8c+W2YnuRUTVkxM0NVJLMOnA9syoG0ao2f9zKXDZ7Bs636/YxmPWTExnoiNjuSxyxryzo2tOHjUuVjwpW/XcPzESb+jGY9YMTGeOq92Al/ffQGXNkniX9/+xF9e+YHVOw76Hct4wIqJ8Vx8qWiG9kzn1T7N2bbvCJcNn8HLU2wrpajxtJjk1WtYRG4VkaUiskhEZmTXPtQUHRc3TuLre87nwgaJvPD1T1wxYibLt9mxlKLCs2KSz17DY1S1sao2w2kROsSrPCY0VIyLYUSf5rzWtzk7Dxyj+8szefarVfaLTxHg5ZZJnr2GVfVAwGhp8nHHe1M0dG2UxLf3ns9VzVN4ddo6ug79jplr7SrkcJav9qAFWrDI1UBX/WN70NaqOuiU+QbiNPQqAXRU1TXZLMvag/qgsDKu2HOC0cuPsfNX5dzkKHrWLUHZmFzbMv0uHNYjhEdO39qD5jUA1wBvBoz3A4bnMn9vYHRey7X2oIWnMDMe+S1TX5i0Sms98oU2fuwrfWfWRs08cTLP14XDelQNj5x+tgfNyxagasB4Kk4v4ZyMBa7wMI8JYbHRkdx3UV2+vOt8GibH87dPl3HlKzNZvHmf39FMPnlZTHLtNQwgIoFt4y4B/rSLY4qXWpXjGHNza17q2Ywd+49yxSszeejjJew5ZBcOhrozaQ+aK1XNFJGsXsORwFvq9hrG2VwaDwwSkc7AcWAvcL1XeUz4EBEub5ZCx3qVGT5lLW/N2MDEZdu5q1NtrmuTRokoOz0qFHlWTCDvXsOqepeX72/CW5nYaB7pVp8eLavyxIQVPPXFSsbM2cSj3erTsV5lRPJ3kNYUDivxJuTVqhzH6AFnM/L6lqBw4+h5XPfWHFZuP5D3i02h8XTLxJhgERE61U/kvNoJvPvjz7w0eQ3dhn1Pu+Qo6qUfpUp8rN8Riz3bMjFhpURUBDe0O4vvHujATe3OYta2TNq/MJXnJ63iwNHjfscr1mzLxISl+FLRPHpJA+rIDmYcKM+Iqet4b/YmBravRb821YmNjvQ7YrFjWyYmrCWUiuClnulMuKMdTVPL8c+JK2n//DTGzN5kVyUXMismpkholBLP6Bta8f7N55BcLpZH/ruUTi9OZ9z8LZywu+UXCismpkhpU7Mi4247l5HXt6RMbBT3fbSYC/81nc8WbbWi4jErJqbIyfrl5/NB7Xitb3NKREZw19hFXPSv6Xy60IqKV6yYmCIrIkLo2iiJiXeexyt9mhMdGcHdHyyi85DpfDRvsx1TCTIrJqbIi4gQujV2isprfZtTqkQkD3y8hPbPT+M/szbajZmCxIqJKTaytlQm3NGOt/q3JLFsDH//bDntnp3CiKlr2X/EzlM5E3aeiSl2RISO9RLpULcyP67/hVenr+P5Sat5ddo6ereuxoC2aSTFl/Q7ZtixYmKKLRGhTc2KtKlZkWVb9/PGd+sZOWMDb83YQPemydx0Xg0aJJf1O2bYsGJiDM55KsN6pfNAl7q8NXMDH8zdzCcLt9K2VkVualeDC+okEBFhVynnxo6ZGBOgaoVSPHZZQ2Y93ImHutZjbcYhBrw9l85DpvPOrI0cPpbpd8SQZcXEmGzEl4rmtvY1+f7BjrzUsxllYqP4v8+Wc87Tk3lywgo27j7sd8SQY7s5xuSiRFQElzdLoXvTZBZu3sfoHzYy+oeNvDVzA+3rJHBdmzTOr5NApO0CWTExJj9EhObVytO8Wnke7VafMXM28d7sTQx4ey5VK5SkV6tq9GhZlUpxMX5H9Y3f7UHvFZEVIrJERCaLSHUv8xgTDJXLxnJ35zr88HBHRvRuTkq5kjz31WraPD2ZQWMW8MO63VntW4oVz7ZMAtqDXojT9mKuiIxX1RUBsy0EWqrqryJyG06L0Gu9ymRMMEVHRnBJkyQuaZLE2oxDvDf7Z8bN38KEJds5q1Jprj27Klc1TyWhTPHYWvG7PehUVf3VHf0Rp7eOMWGnVuU4HrusIXMe7cyL1zSlUlwJnvlyFW2ensyt78xn8a5MMov4tUBeHjNJATYHjG8BWucy/43Alx7mMcZzsdGRXNUilatapLI246BzvsqCrXx1+Dfe+2kKf2meyjUtU6mZENqtQgvCy17D1wBd9I+9hlup6h3ZzNsXGARcoKp/6rZkvYb9YRmDI/OkMnvTYebsiWLp7hOcVKgZH0HblChaJ0VROjo0fgkK5V7DbYBJAeODgcHZzNcZWAlUzs9yrddw4bGMwZOVc+eBI/r69LV60ZDpWv2hCVr7kYl66zvzdNKy7Xrs+ImQyJgT8ug17OVuzu/tQYGtOO1BewfOICLpwOtAV1XN8DCLMSGhcplYbjm/JjefV4Pl2w4wbsEWxi/axpfLdlCuVDSXNE7i8mYptKxePuxO3/e7PejzQBzwkdudbZOqdvcqkzGhQkRolBJPo5R4HulWnxlrd/Ppwq18smAr783eREq5klzaNInuTZNpkFQ2LLoX+t0etLOX729MOIiOjKBD3cp0qFuZw8cy+WbFTj5btJWR32/g9enrqZFQmkubJHNZkyRqJ5bxO26O7AxYY0JI6ZgorkhP4Yr0FH45/BtfLtvOhMXbGT5lDcMmr6FOYhzdGidxaZMkalUOrcJixcSYEFWhdAn6tK5On9bVyTh4lK+W7WDC4u28NHkNQ79dQ+3KcVzcqApdGyVRP6mM77tCVkyMCQOVy8RyXZs0rmuTxs4DTmGZuHQ7w6euZdiUtaRVLEWXhlW4qGEV0quW8+XgrRUTY8JMYtlYrj83jevPTWPXwWN8s2InXy7bzsgZG3j9u/UklInhwgaJXNQgkTY1KxITVTitUq2YGBPGEsrE0Lt1NXq3rsb+I8eZsmon36zYyacLtzJm9ibiYqK4oE4CnRs4B3jLlSrhWRYrJsYUEfElo7kyPZUr01M5evwEP6zbzTcrdjJ5ZQZfLN1OhEDL6hXoWL8ynepVplbluKAeZ7FiYkwRFBsdScd6iXSsl8jJk8rSrfuZvHIn367M4JkvV/HMl6uoWqHk7z9JX1An4Yzf04qJMUVcRITQtGo5mlYtx70X1WX7/iNMWZXB1FW7+GjeFiavzGDGQx3O+H2smBhTzCTFl/z9J+ejx0+wZe+vQdndsRtKG1OMxUZHBu3kNysmxpigsGJijAkKKybGmKCwYmKMCQorJsaYoPDsHrBeEZFdwM+5zFIJ2F1Icc5EOOS0jMETDjnzylhdVXM8uy3sikleRGSe5nbT2xARDjktY/CEQ84zzWi7OcaYoLBiYowJiqJYTN7wO0A+hUNOyxg84ZDzjDIWuWMmxhh/FMUtE2OMD4pUMRGRriKyWkTWisjDfucBEJGqIjJVRFaKyHIRucudXkFEvhGRNe5/y4dA1kgRWSgiE9zxs0RktpvxAxHx7jZd+c9YTkQ+FpFV7jptE2rrUkTucf+tl4nI+yISGwrrUkTeEpEMEVkWMC3bdSeOYe53aYmINM9r+UWmmIhIJDACuBhoAPQSkQb+pgIgE7hPVesD5wAD3VwPA5NVtTYw2R332104rVqzPAv8y824F6e5vN9eAr5S1XpAU5y8IbMuRSQFuBNoqaqNcBrQ9SQ01uXbQNdTpuW07i4GarvDLcCreS49t96h4TSQz97Gfg/AZ8CFwGogyZ2WBKz2OVeq+z9TR2ACIDgnMEVlt359ylgW2IB7rC9gesisSyAF2AxUwLlf0ASgS6isSyANWJbXusNp29sru/lyGorMlgn/+0fMssWdFjJEJA1IB2YDiaq6HcD9b2X/kgEwFHgQOOmOVwT2qWqmOx4K67MGsAsY5e6OvSkipQmhdamqW4EXgE3AdmA/MJ/QW5dZclp3p/19KkrFJLtbRYXMT1UiEgeMA+5W1QN+5wkkIpcCGao6P3ByNrP6vT6jgObAq6qaDhwmNHYPf+cec7gcOAtIBkrj7DKcyu91mZfT/vcvSsVkC1A1YDwV2OZTlj8QkWicQvKeqn7iTt4pIknu87VCDykAAALJSURBVElAhl/5gLZAdxHZCIzF2dUZCpQTkaxbe4bC+twCbFHV2e74xzjFJZTWZWdgg6ruUtXjwCfAuYTeusyS07o77e9TUSomc4Ha7lHzEjgHvcb7nAlxbq45ElipqkMCnhoPXO8+vh7nWIovVHWwqqaqahrOepuiqn2AqcDV7my+ZgRQ1R3AZhGp607qBKwghNYlzu7NOSJSyv23z8oYUusyQE7rbjxwnfurzjnA/qzdoRz5daDKo4NL3YCfgHXAo37ncTO1w9k8XAIscoduOMckJgNr3P9W8Durm7c9MMF9XAOYA6wFPgJiQiBfM2Ceuz4/BcqH2roE/gGsApYB7wAxobAugfdxjuMcx9nyuDGndYezmzPC/S4txfl1Ktfl2xmwxpigKEq7OcYYH1kxMcYEhRUTY0xQWDExxgSFFRNjTFBYMTGnTUROiMiigCFoZ6GKSFrgVa0mfFjjclMQR1S1md8hTGixLRMTNCKyUUSeFZE57lDLnV5dRCa798WYLCLV3OmJIvJfEVnsDue6i4oUkX+79wT5WkRK+vahTL5ZMTEFUfKU3ZxrA547oKqtgJdxru/BffwfVW0CvAcMc6cPA6aralOca2yWu9NrAyNUtSGwD7jK489jgsDOgDWnTUQOqWpcNtM3Ah1Vdb17ceMOVa0oIrtx7oVx3J2+XVUridNQLVVVjwUsIw34Rp2b9SAiDwHRqvqU95/MnAnbMjHBpjk8zmme7BwLeHwCO7YXFqyYmGC7NuC/s9zHP+BcjQzQB5jhPp4M3Aa/33+2bGGFNMFnFd8UREkRWRQw/pWqZv08HCMis3H+UPVyp90JvCUiD+DcKW2AO/0u4A0RuRFnC+Q2nKtaTRiyYyYmaNxjJi1VNdQbdBsP2G6OMSYobMvEGBMUtmVijAkKKybGmKCwYmKMCQorJsaYoLBiYowJCismxpig+P9/tOwmwu9lfgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(4,3))\n",
    "plt.plot(epoch,loss_list)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Epoch vs Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2.3: Adam Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated value of w is 0.6921482822190134 in Epoch 1\n",
      "The updated value of w is 0.6851882572423449 in Epoch 2\n",
      "The updated value of w is 0.6759305613721335 in Epoch 3\n",
      "The updated value of w is 0.6652847786882699 in Epoch 4\n",
      "The updated value of w is 0.6537543245491555 in Epoch 5\n",
      "The updated value of w is 0.641668538167386 in Epoch 6\n",
      "The updated value of w is 0.6292590046062251 in Epoch 7\n",
      "The updated value of w is 0.6166945983821501 in Epoch 8\n",
      "The updated value of w is 0.6041007663099651 in Epoch 9\n",
      "The updated value of w is 0.5915714201929958 in Epoch 10\n",
      "The updated value of w is 0.5791768591465387 in Epoch 11\n",
      "The updated value of w is 0.5669693400043992 in Epoch 12\n",
      "The updated value of w is 0.5549871487400516 in Epoch 13\n",
      "The updated value of w is 0.5432576613420681 in Epoch 14\n",
      "The updated value of w is 0.531799693065024 in Epoch 15\n",
      "The updated value of w is 0.5206253291894726 in Epoch 16\n",
      "The updated value of w is 0.5097413677905887 in Epoch 17\n",
      "The updated value of w is 0.49915046603034824 in Epoch 18\n",
      "The updated value of w is 0.48885205615705246 in Epoch 19\n",
      "The updated value of w is 0.4788430803114891 in Epoch 20\n",
      "The updated value of w is 0.46911858133705986 in Epoch 21\n",
      "The updated value of w is 0.45967217826336915 in Epoch 22\n",
      "The updated value of w is 0.4504964488725314 in Epoch 23\n",
      "The updated value of w is 0.4415832370651968 in Epoch 24\n",
      "The updated value of w is 0.432923899163483 in Epoch 25\n",
      "The updated value of w is 0.4245095005156222 in Epoch 26\n",
      "The updated value of w is 0.4163309715930014 in Epoch 27\n",
      "The updated value of w is 0.40837923104724566 in Epoch 28\n",
      "The updated value of w is 0.4006452818176282 in Epoch 29\n",
      "The updated value of w is 0.39312028527006004 in Epoch 30\n",
      "The updated value of w is 0.38579561745072416 in Epoch 31\n",
      "The updated value of w is 0.37866291080643405 in Epoch 32\n",
      "The updated value of w is 0.37171408412661106 in Epoch 33\n",
      "The updated value of w is 0.3649413629723186 in Epoch 34\n",
      "The updated value of w is 0.3583372924556444 in Epoch 35\n",
      "The updated value of w is 0.3518947439016404 in Epoch 36\n",
      "The updated value of w is 0.34560691665204046 in Epoch 37\n",
      "The updated value of w is 0.3394673360446289 in Epoch 38\n",
      "The updated value of w is 0.33346984841594507 in Epoch 39\n",
      "The updated value of w is 0.32760861382112594 in Epoch 40\n",
      "The updated value of w is 0.3218780970374349 in Epoch 41\n",
      "The updated value of w is 0.3162730573128301 in Epoch 42\n",
      "The updated value of w is 0.31078853723394506 in Epoch 43\n",
      "The updated value of w is 0.3054198510160241 in Epoch 44\n",
      "The updated value of w is 0.3001625724580027 in Epoch 45\n",
      "The updated value of w is 0.2950125227570117 in Epoch 46\n",
      "The updated value of w is 0.28996575833626287 in Epoch 47\n",
      "The updated value of w is 0.28501855880711396 in Epoch 48\n",
      "The updated value of w is 0.28016741515889143 in Epoch 49\n",
      "The updated value of w is 0.27540901824775127 in Epoch 50\n",
      "The updated value of w is 0.27074024763764215 in Epoch 51\n",
      "The updated value of w is 0.2661581608316008 in Epoch 52\n",
      "The updated value of w is 0.261659982919589 in Epoch 53\n",
      "The updated value of w is 0.2572430966593695 in Epoch 54\n",
      "The updated value of w is 0.25290503299912703 in Epoch 55\n",
      "The updated value of w is 0.24864346204433802 in Epoch 56\n",
      "The updated value of w is 0.24445618446648565 in Epoch 57\n",
      "The updated value of w is 0.24034112334739102 in Epoch 58\n",
      "The updated value of w is 0.2362963164499812 in Epoch 59\n",
      "The updated value of w is 0.23231990890408952 in Epoch 60\n",
      "The updated value of w is 0.2284101462942435 in Epoch 61\n",
      "The updated value of w is 0.2245653681352368 in Epoch 62\n",
      "The updated value of w is 0.22078400172050774 in Epoch 63\n",
      "The updated value of w is 0.21706455632788468 in Epoch 64\n",
      "The updated value of w is 0.21340561776705066 in Epoch 65\n",
      "The updated value of w is 0.20980584325305648 in Epoch 66\n",
      "The updated value of w is 0.20626395659035968 in Epoch 67\n",
      "The updated value of w is 0.2027787436521225 in Epoch 68\n",
      "The updated value of w is 0.19934904813985568 in Epoch 69\n",
      "The updated value of w is 0.19597376760891713 in Epoch 70\n",
      "The updated value of w is 0.19265184974583682 in Epoch 71\n",
      "The updated value of w is 0.18938228888395392 in Epoch 72\n",
      "The updated value of w is 0.18616412274436722 in Epoch 73\n",
      "The updated value of w is 0.18299642938974162 in Epoch 74\n",
      "The updated value of w is 0.17987832437904933 in Epoch 75\n",
      "The updated value of w is 0.17680895811187414 in Epoch 76\n",
      "The updated value of w is 0.17378751335141399 in Epoch 77\n",
      "The updated value of w is 0.17081320291586585 in Epoch 78\n",
      "The updated value of w is 0.16788526752835725 in Epoch 79\n",
      "The updated value of w is 0.1650029738160952 in Epoch 80\n",
      "The updated value of w is 0.1621656124498666 in Epoch 81\n",
      "The updated value of w is 0.15937249641548834 in Epoch 82\n",
      "The updated value of w is 0.15662295940923116 in Epoch 83\n",
      "The updated value of w is 0.1539163543496697 in Epoch 84\n",
      "The updated value of w is 0.15125205199880334 in Epoch 85\n",
      "The updated value of w is 0.14862943968567965 in Epoch 86\n",
      "The updated value of w is 0.1460479201261104 in Epoch 87\n",
      "The updated value of w is 0.14350691033241936 in Epoch 88\n",
      "The updated value of w is 0.14100584060748994 in Epoch 89\n",
      "The updated value of w is 0.13854415361769515 in Epoch 90\n",
      "The updated value of w is 0.13612130353958338 in Epoch 91\n",
      "The updated value of w is 0.13373675527548967 in Epoch 92\n",
      "The updated value of w is 0.1313899837334938 in Epoch 93\n",
      "The updated value of w is 0.12908047316741644 in Epoch 94\n",
      "The updated value of w is 0.12680771657277795 in Epoch 95\n",
      "The updated value of w is 0.12457121513487743 in Epoch 96\n",
      "The updated value of w is 0.12237047772536831 in Epoch 97\n",
      "The updated value of w is 0.12020502044391476 in Epoch 98\n",
      "The updated value of w is 0.11807436620170371 in Epoch 99\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-8 #Taking the recommended values\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "learning_rate = 0.001\n",
    "v = np.zeros(len(w))\n",
    "m = np.zeros(len(w))\n",
    "mt = np.zeros(len(w))\n",
    "vt = np.zeros(len(w))\n",
    "epoch = range(1,100)\n",
    "w3 = np.copy(w)\n",
    "loss_list = []\n",
    "for i in epoch:\n",
    "    for j in range(len(X)):\n",
    "        loss1, y_dash_val, loss_dict1 = forward_propagation(X[j],y[j],w3)\n",
    "        dw = backward_propagation(loss1, y_dash_val, X[j], y[j], w3, loss_dict1)\n",
    "    m = beta1*m + [x * (1-beta1) for x in dw]\n",
    "    v = beta2*v + [x * (1-beta2) for x in list(np.power(dw,2))]\n",
    "    w3 = w3 - [x * learning_rate for x in m] / (np.sqrt(v)) + eps\n",
    "    \n",
    "    loss_list.append(loss1)\n",
    "  \n",
    "    print('The updated value of w is {} in Epoch {}'.format(loss1,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(4,3))\n",
    "plt.plot(epoch,loss_list)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Epoch vs Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "1. The Vanilla Update did a decent job of reducing the Loss. It reduced the loss by about 0.133 in 100 epochs.\n",
    "2. The Momentum Update did an excellent job in reducing the Loss. It reduced the loss from 0.692 to 0.151, which is excellent.\n",
    "3. The Adam Update did the best out of the 3. It reduced the loss from 0.692 to 0.118, which is the least loss that we have got.\n",
    "4. So we can say that Adam Update is best to reduce the loss the most in less number of Epochs than Momentum and Vanilla Update"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Backpropagation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
